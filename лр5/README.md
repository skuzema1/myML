# Лабораторная работа №5
# Машины опорных векторов
# Преобразование исходных данных и построение моделей
# Стандартизация и переход к главным компонентам
Предварительно преобразуем пространство исходных показателей с помощью метода главных компонент
![image](https://user-images.githubusercontent.com/93386717/207196595-bb20f717-9979-44d9-a7e4-d7d750de11f6.png)
  
# Регрессия на главные компоненты (PCR)
Пересчитаем объясняющие показатели в главные компоненты.
  
Доли объяснённой дисперсии по компонентам в PLS:
 [0.272 0.175 0.065 0.062 0.044 0.04  0.038 0.038 0.037 0.035 0.032 0.031
 0.026 0.024 0.022 0.017 0.011 0.011 0.008 0.006 0.003 0.002 0.001 0.001] 
Общая сумма долей: 1.0
Первые четыре главные компоненты объясняют более 50% разброса
  
Acc с перекрёстной проверкой 
для модели pca_logit : 0.796

  
# Случайный лес
У модели случайного леса два настроечных параметра: количество деревьев  и количество признаков для построения отдельного дерева . Настроим сеточный поиск для их подбора.
Acc с перекрёстной проверкой 
для модели random_forest_GS : 0.817

  
# Метод kNN
Реализуем метод k-ближайших соседей с преобразованием PCA.
Acc с перекрёстной проверкой 
для модели sc_pca_knn : 0.816

  
# Прогноз на отложенные наблюдения по лучшей модели
Все модели показывают хорошую точность по показателю , при этом самой точной оказывается модель random_. Сделаем прогноз на отложенные наблюдения

  
![image](https://user-images.githubusercontent.com/93386717/207196776-7e2e0bb3-def4-48f7-bef5-4a20d1e7778c.png)
